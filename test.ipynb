{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = '/home/yuxuan/project/NeuralSurfaceField/Data/BuFF/buff_release_rot_const/sequences/00096/shortlong_hips/shortlong_hips_000216_cano.npy'\n",
    "\n",
    "cano = np.load(path, allow_pickle=True).item()\n",
    "cano_verts = cano['cano_points']\n",
    "cano_normals = cano['cano_normals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(cano_verts)\n",
    "pcd.normals = o3d.utility.Vector3dVector(cano_normals)\n",
    "\n",
    "# write point cloud\n",
    "o3d.io.write_point_cloud(\"visualization/00096_shortlong_hips_000216_cano.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 569/569 [00:04<00:00, 137.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, in total 569 train examples.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dataloaders.dataloader_buff import DataLoader_Buff_depth\n",
    "\n",
    "splt_file = '/home/yuxuan/project/NeuralSurfaceField/assets/data_split/buff_male_train_val.pkl' \n",
    "subject_index_dict = {}\n",
    "subject_index_dict.update({\"00032_shortlong\": 0,\n",
    "                            \"00096_shortlong\": 1})\n",
    "train_dataset = DataLoader_Buff_depth(mode='train', batch_size=2, num_workers=4, split_file=splt_file, subject_index_dict=subject_index_dict)\n",
    "train_loader = train_dataset.get_loader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "# write function which uses open3d to write point cloud\n",
    "def write_pcd(path, points, normals):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "    o3d.io.write_point_cloud(path, pcd)\n",
    "\n",
    "path_cano = '/home/yuxuan/project/NeuralSurfaceField/visualization/cano.ply'\n",
    "path_posed = '/home/yuxuan/project/NeuralSurfaceField/visualization/posed.ply'\n",
    "\n",
    "# write cano point cloud\n",
    "write_pcd(path_cano, batch['cano_points'][0].cpu().numpy(), batch['cano_normals'][0].cpu().numpy())\n",
    "# write posed point cloud\n",
    "write_pcd(path_posed, batch['scan_points'][0].cpu().numpy().transpose(), batch['scan_normals'][0].cpu().numpy().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "dict_ = np.load('/home/yuxuan/project/NeuralSurfaceField/Data_scan/BuFF/buff_release/sequences/00159/shortshort_twist_tilt_left/shortshort_twist_tilt_left.000050.npz')\n",
    "\n",
    "# o3d point cloud visualization\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(dict_['v_posed'])\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "split_file = '/mnt/qb/work/ponsmoll/yxue80/project/NeuralSurfaceField/assets/data_split/buff_male_train_val.pkl'\n",
    "\n",
    "with open(split_file, \"rb\") as f:\n",
    "    split = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.global_variable import ROOT_DIR\n",
    "import os\n",
    "\n",
    "split_org = {\n",
    "    'train': [],\n",
    "    'val': []\n",
    "}\n",
    "\n",
    "for subj_train in split['train']:\n",
    "    if subj_train.split('/')[5].startswith('shortlong'):\n",
    "        split_org['train'].append(subj_train)\n",
    "\n",
    "\n",
    "for subj_val in split['val']:\n",
    "    if subj_val.split('/')[5].startswith('shortlong'):\n",
    "        split_org['val'].append(subj_val)\n",
    "\n",
    "\n",
    "pkl.dump(split_org, open(split_file.replace('buff_male_train_val.pkl', 'buff_male_shapefusion.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30000, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['cano_points'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from: /mnt/qb/work/ponsmoll/yxue80/project/shapefusion/experiments/PoseImplicit_exp_id_808/checkpoints/checkpoint_epoch_2150.tar\n",
      "dict_keys(['epoch', 'optimizer_state_dict', 'scheduler_state_dict', 'feat_optimizer_state_dict', 'feat_scheduler_state_dict', 'pose_encoder_state_dict', 'shape_geometry_decoder_state_dict', 'conditional_ndf_state_dict'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# load old checkpoint\n",
    "shapefusion_path = '/mnt/qb/work/ponsmoll/yxue80/project/shapefusion/experiments/PoseImplicit_exp_id_808'\n",
    "shapefusion_checkpoint_path = os.path.join(shapefusion_path, 'checkpoints', 'checkpoint_epoch_2150.tar')\n",
    "\n",
    "print('Loaded checkpoint from: {}'.format(shapefusion_checkpoint_path))\n",
    "checkpoint = torch.load(shapefusion_checkpoint_path)\n",
    "\n",
    "print(checkpoint.keys())\n",
    "\n",
    "# save to new checkpoint\n",
    "path = 'checkpoint_epoch_{}.tar'.format(checkpoint['epoch'])\n",
    "if not os.path.exists(path):\n",
    "    model_weights = {'epoch': checkpoint['epoch'],\n",
    "                    'optimizer_state_dict': checkpoint['optimizer_state_dict'], \n",
    "                    'scheduler_state_dict': checkpoint['scheduler_state_dict'],\n",
    "                    'feat_optimizer_state_dict': checkpoint['feat_optimizer_state_dict'],\n",
    "                    'feat_scheduler_state_dict': checkpoint['feat_scheduler_state_dict'],\n",
    "                    'pose_encoder_state_dict': checkpoint['pose_encoder_state_dict'],\n",
    "                    'nsf_decoder_state_dict': checkpoint['shape_geometry_decoder_state_dict']}\n",
    "    torch.save(model_weights, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

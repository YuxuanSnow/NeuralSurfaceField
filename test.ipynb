{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from libs.global_variable import ROOT_DIR\n",
    "\n",
    "path = ROOT_DIR + 'Data/BuFF/buff_release_rot_const/sequences/00096/shortshort_hips/shortshort_hips_000010_cano.npy'\n",
    "\n",
    "cano = np.load(path, allow_pickle=True).item()\n",
    "cano_verts = cano['cano_points']\n",
    "cano_normals = cano['cano_normals']\n",
    "valid_mask = cano['valid_mask']\n",
    "\n",
    "path_scan = ROOT_DIR + 'Data/BuFF/buff_release_rot_const/sequences/00096/shortshort_hips/shortshort_hips_000010.npy'\n",
    "\n",
    "scan = np.load(path_scan, allow_pickle=True).item()\n",
    "scan_verts = scan['points_posed_cloth']\n",
    "scan_normals = scan['normals_posed_cloth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_repeated_idx(num_points_input, num_points):\n",
    "\n",
    "    assert(num_points_input <= num_points)\n",
    "    idx_org = np.arange(0, num_points_input)\n",
    "\n",
    "    num_points_rest = num_points - num_points_input\n",
    "    if num_points_rest <= num_points_input:\n",
    "        idx_rest = np.random.choice(np.arange(0, num_points_input), num_points_rest, replace=False)\n",
    "    elif num_points_rest > num_points_input:\n",
    "        num_points_rest_1 = num_points_input\n",
    "        idx_rest_1 = np.random.choice(np.arange(0, num_points_input), num_points_rest_1, replace=False)\n",
    "        num_points_rest_2 = num_points_rest - num_points_rest_1\n",
    "        idx_rest_2 = np.random.choice(np.arange(0, num_points_input), num_points_rest_2, replace=False)\n",
    "        idx_rest = np.concatenate((idx_rest_1, idx_rest_2))\n",
    "\n",
    "    idx_list = np.concatenate((idx_org, idx_rest))\n",
    "\n",
    "    return idx_list\n",
    "\n",
    "idx_list = _get_repeated_idx(cano_verts.shape[0], 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24169,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cano_verts[idx_list].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_verts.transpose()[valid_mask][idx_list].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(cano_verts)\n",
    "pcd.normals = o3d.utility.Vector3dVector(cano_normals)\n",
    "\n",
    "# write point cloud\n",
    "o3d.io.write_point_cloud(\"visualization/00096_shortlong_hips_000216_cano.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 569/569 [00:04<00:00, 137.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, in total 569 train examples.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dataloaders.dataloader_buff import DataLoader_Buff_depth\n",
    "\n",
    "splt_file = '/home/yuxuan/project/NeuralSurfaceField/assets/data_split/buff_female_train_val.pkl' \n",
    "subject_index_dict = {}\n",
    "subject_index_dict.update({\"00032_shortlong\": 0,\n",
    "                            \"00096_shortlong\": 1})\n",
    "train_dataset = DataLoader_Buff_depth(mode='train', batch_size=2, num_workers=4, split_file=splt_file, subject_index_dict=subject_index_dict)\n",
    "train_loader = train_dataset.get_loader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "# write function which uses open3d to write point cloud\n",
    "def write_pcd(path, points, normals):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "    o3d.io.write_point_cloud(path, pcd)\n",
    "\n",
    "path_cano = '/home/yuxuan/project/NeuralSurfaceField/visualization/cano.ply'\n",
    "path_posed = '/home/yuxuan/project/NeuralSurfaceField/visualization/posed.ply'\n",
    "\n",
    "# write cano point cloud\n",
    "write_pcd(path_cano, batch['cano_points'][0].cpu().numpy(), batch['cano_normals'][0].cpu().numpy())\n",
    "# write posed point cloud\n",
    "write_pcd(path_posed, batch['scan_points'][0].cpu().numpy().transpose(), batch['scan_normals'][0].cpu().numpy().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "dict_ = np.load('/home/yuxuan/project/NeuralSurfaceField/Data_scan/BuFF/buff_release/sequences/00159/shortshort_twist_tilt_left/shortshort_twist_tilt_left.000050.npz')\n",
    "\n",
    "# o3d point cloud visualization\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(dict_['v_posed'])\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "split_file = '/mnt/qb/work/ponsmoll/yxue80/project/NeuralSurfaceField/assets/data_split/buff_female_train_val.pkl'\n",
    "\n",
    "with open(split_file, \"rb\") as f:\n",
    "    split = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.global_variable import ROOT_DIR\n",
    "import os\n",
    "\n",
    "split_org = {\n",
    "    'train': [],\n",
    "    'val': []\n",
    "}\n",
    "\n",
    "for subj_train in split['train']:\n",
    "    split_org['train'].append(subj_train.replace('Data_male', 'Data'))\n",
    "\n",
    "for subj_val in split['val']:\n",
    "    split_org['val'].append(subj_val.replace('Data_male', 'Data'))\n",
    "\n",
    "\n",
    "pkl.dump(split_org, open(split_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30000, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['cano_points'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from: /mnt/qb/work/ponsmoll/yxue80/project/shapefusion/experiments/PoseImplicit_exp_id_808/checkpoints/checkpoint_epoch_2150.tar\n",
      "dict_keys(['epoch', 'optimizer_state_dict', 'scheduler_state_dict', 'feat_optimizer_state_dict', 'feat_scheduler_state_dict', 'pose_encoder_state_dict', 'shape_geometry_decoder_state_dict', 'conditional_ndf_state_dict'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# load old checkpoint\n",
    "shapefusion_path = '/mnt/qb/work/ponsmoll/yxue80/project/shapefusion/experiments/PoseImplicit_exp_id_808'\n",
    "shapefusion_checkpoint_path = os.path.join(shapefusion_path, 'checkpoints', 'checkpoint_epoch_2150.tar')\n",
    "\n",
    "print('Loaded checkpoint from: {}'.format(shapefusion_checkpoint_path))\n",
    "checkpoint = torch.load(shapefusion_checkpoint_path)\n",
    "\n",
    "print(checkpoint.keys())\n",
    "\n",
    "# save to new checkpoint\n",
    "path = 'checkpoint_epoch_{}.tar'.format(checkpoint['epoch'])\n",
    "if not os.path.exists(path):\n",
    "    model_weights = {'epoch': checkpoint['epoch'],\n",
    "                    'optimizer_state_dict': checkpoint['optimizer_state_dict'], \n",
    "                    'scheduler_state_dict': checkpoint['scheduler_state_dict'],\n",
    "                    'feat_optimizer_state_dict': checkpoint['feat_optimizer_state_dict'],\n",
    "                    'feat_scheduler_state_dict': checkpoint['feat_scheduler_state_dict'],\n",
    "                    'pose_encoder_state_dict': checkpoint['pose_encoder_state_dict'],\n",
    "                    'nsf_decoder_state_dict': checkpoint['shape_geometry_decoder_state_dict']}\n",
    "    torch.save(model_weights, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 4.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor with requires_grad enabled\n",
    "tensor = torch.tensor([1, 2, 3], dtype=torch.float32, requires_grad=False)\n",
    "tensor2 = torch.tensor([1, 2, 4], dtype=torch.float32, requires_grad=False)\n",
    "\n",
    "mask = tensor > 2\n",
    "\n",
    "tensor[mask] = tensor2[mask]\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
